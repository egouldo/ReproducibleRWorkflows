@Article{Chirigati:2016co,
author = {Chirigati, Fernando and Capone, Rebecca and Rampin, R{\'e}mi and Freire, Juliana and Shasha, Dennis}, 
title = {A collaborative approach to computational reproducibility}, 
journal = {Information Systems}, 
volume = {59}, 
pages = {95--97}, 
year = {2016}, 
keywords = {computational; reproducibility; Reproducible Research; workflow}}

@Article{Bino:2015fa,
author = {Bino, Gilad and Sisson, Scott A and Kingsford, Richard T and Thomas, Rachael F and Bowen, Sharon}, 
editor = {Kardol, Paul}, 
title = {Developing state and transition models of floodplain vegetation dynamics as a tool for conservation decision-making: a case study of the Macquarie Marshes Ramsar wetland}, 
journal = {Journal of Applied Ecology}, 
volume = {52}, 
number = {3}, 
pages = {654--664}, 
year = {2015} }

@Article{Kumar:2013gj,
author = {Kumar, Ramasamy Rajesh and Park, Bong Ju and Cho, Jae Young}, 
title = {Application and environmental risks of livestock manure}, 
journal = {Journal of the Korean Society for Applied Biological Chemistry}, 
volume = {56}, 
number = {5}, 
pages = {497--503}, 
year = {2013}, 
keywords = {\#comparison; \#faecal pollution; \#quality; \#whole; manure; point-source}}

@Article{Ram:2013,
author = {Ram, Karthik}, 
title = {Git can facilitate greater reproducibility and increased transparency in science.}, 
journal = {Source code for biology and medicine}, 
volume = {8}, 
number = {1}, 
pages = {7}, 
year = {2013}, 
abstract = {BACKGROUND:Reproducibility is the hallmark of good science. Maintaining a high degree of transparency in scientific reporting is essential not just for gaining trust and credibility within the scientific community but also for facilitating the development of new ideas. Sharing data and computer code associated with publications is becoming increasingly common, motivated partly in response to data deposition requirements from journals and mandates from funders. Despite this increase in transparency, it is still difficult to reproduce or build upon the findings of most scientific publications without access to a more complete workflow.}, 
location = {Environmental Science, Policy, and Management, University of California, Berkeley, Berkeley, CA 94720, USA. karthik.ram@berkeley.edu.}, 
keywords = {git; Reproducible Research; Research Methods; version control}}

@Article{Chapple:2011vd,
author = {Chapple, R S and Ramp, D and Bradstock, R A and al, et}, 
title = {Integrating science into management of ecosystems in the Greater Blue Mountains}, 
journal = {Environmental management}, 
volume = {48}, 
number = {4}, 
year = {2011}, 
abstract = {Abstract Effective management of large protected conservation areas is challenged by political, institutional and environmental complexity and inconsistency. Knowledge generation and its uptake into management are crucial to address these challenges. We.}, 
keywords = {Adaptive management; Biodiversity; Bushfire management; Conservation; Knowledge generation and uptake; Protected area management; Wild-dog management; Papers_flagged}}

@Article{KATTGE:2011fc,
author = {KATTGE, J and D{\'I}AZ, S and D{\'I}AZ, S and LAVOREL, S and LAVOREL, S and PRENTICE, I C and PRENTICE, I C and LEADLEY, P and LEADLEY, P and B{\"O}NISCH, G and B{\"O}NISCH, G and GARNIER, E and GARNIER, E and WESTOBY, M and WESTOBY, M and REICH, P B and REICH, P B and WRIGHT, I J and WRIGHT, I J and CORNELISSEN, J H C and CORNELISSEN, J H C and VIOLLE, C and VIOLLE, C and HARRISON, S P and HARRISON, S P and Van BODEGOM, P M and Van BODEGOM, P M and REICHSTEIN, M and REICHSTEIN, M and ENQUIST, B J and ENQUIST, B J and SOUDZILOVSKAIA, N A and SOUDZILOVSKAIA, N A and ACKERLY, D D and ACKERLY, D D and ANAND, M and ANAND, M and ATKIN, O and ATKIN, O and BAHN, M and BAHN, M and BAKER, T R and BAKER, T R and BALDOCCHI, D and BALDOCCHI, D and BEKKER, R and BEKKER, R and BLANCO, C C and BLANCO, C C and BLONDER, B and BLONDER, B and BOND, W J and BOND, W J and BRADSTOCK, R and BRADSTOCK, R and BUNKER, D E and BUNKER, D E and CASANOVES, F and CASANOVES, F and CAVENDER-BARES, J and CAVENDER-BARES, J and CHAMBERS, J Q and CHAMBERS, J Q and CHAPIN, III, F S and CHAPIN, III, F S and CHAVE, J and CHAVE, J and COOMES, D and COOMES, D and CORNWELL, W K and CORNWELL, W K and CRAINE, J M and CRAINE, J M and DOBRIN, B H and DOBRIN, B H and DUARTE, L and DUARTE, L and DURKA, W and DURKA, W and ELSER, J and ELSER, J and ESSER, G and ESSER, G and ESTIARTE, M and ESTIARTE, M and FAGAN, W F and FAGAN, W F and FANG, J and FANG, J and FERN{\'A}NDEZ-M{\'E}NDEZ, F and FERN{\'A}NDEZ-M{\'E}NDEZ, F and FIDELIS, A and FIDELIS, A and FINEGAN, B and FINEGAN, B and FLORES, O and FLORES, O and FORD, H and FORD, H and FRANK, D and FRANK, D and FRESCHET, G T and FRESCHET, G T and FYLLAS, N M and FYLLAS, N M and GALLAGHER, R V and GALLAGHER, R V and GREEN, W A and GREEN, W A and GUTIERREZ, A G and GUTIERREZ, A G and HICKLER, T and HICKLER, T and HIGGINS, S I and HIGGINS, S I and HODGSON, J G and HODGSON, J G and JALILI, A and JALILI, A and JANSEN, S and JANSEN, S and JOLY, C A and JOLY, C A and KERKHOFF, A J and KERKHOFF, A J and KIRKUP, D and KIRKUP, D and KITAJIMA, K and KITAJIMA, K and KLEYER, M and KLEYER, M and KLOTZ, S and KLOTZ, S and KNOPS, J M H and KNOPS, J M H and KRAMER, K and KRAMER, K and K{\"U}HN, I and K{\"U}HN, I and KUROKAWA, H and KUROKAWA, H and LAUGHLIN, D and LAUGHLIN, D and LEE, T D and LEE, T D and LEISHMAN, M and LEISHMAN, M and LENS, F and LENS, F and LENZ, T and LENZ, T and LEWIS, S L and LEWIS, S L and LLOYD, J and LLOYD, J and LLUSI{\`A}, J and LLUSI{\`A}, J and LOUAULT, F and LOUAULT, F and MA, S and MA, S and MAHECHA, M D and MAHECHA, M D and MANNING, P and MANNING, P and MASSAD, T and MASSAD, T and MEDLYN, B E and MEDLYN, B E and MESSIER, J and MESSIER, J and MOLES, A T and MOLES, A T and M{\"U}LLER, S C and M{\"U}LLER, S C and NADROWSKI, K and NADROWSKI, K and Naeem, Shahid and NIINEMETS, {\"U} and NIINEMETS, {\"U} and N{\"O}LLERT, S and N{\"O}LLERT, S and N{\"U}SKE, A and N{\"U}SKE, A and OGAYA, R and OGAYA, R and OLEKSYN, J and OLEKSYN, J and ONIPCHENKO, V G and ONIPCHENKO, V G and ONODA, Y and ONODA, Y and ORDO{\~N}EZ, J and ORDO{\~N}EZ, J and OVERBECK, G and OVERBECK, G and OZINGA, W A and OZINGA, W A and PATI{\~N}O, S and PATI{\~N}O, S and PAULA, S and PAULA, S and PAUSAS, J G and PAUSAS, J G and PE{\~N}UELAS, J and PE{\~N}UELAS, J and PHILLIPS, O L and Phillips, O L and PILLAR, V and PILLAR, V and POORTER, H and POORTER, H and POORTER, L and POORTER, L and POSCHLOD, P and POSCHLOD, P and PRINZING, A and PRINZING, A and PROULX, R and PROULX, R and RAMMIG, A and RAMMIG, A and REINSCH, S and REINSCH, S and REU, B and REU, B and SACK, L and SACK, L and SALGADO-NEGRET, B and SALGADO-NEGRET, B and SARDANS, J and SARDANS, J and SHIODERA, S and SHIODERA, S and SHIPLEY, B and SHIPLEY, B and SIEFERT, A and SIEFERT, A and SOSINSKI, E and SOSINSKI, E and SOUSSANA, J F and SOUSSANA, J F and SWAINE, E and SWAINE, E and SWENSON, N and SWENSON, N and THOMPSON, K and THOMPSON, K and THORNTON, P and THORNTON, P and WALDRAM, M and WALDRAM, M and WEIHER, E and WEIHER, E and WHITE, M and White, Matt D and WHITE, S and WRIGHT, S J and WRIGHT, S J and YGUEL, B and YGUEL, B and ZAEHLE, S and ZAEHLE, S and ZANNE, A E and ZANNE, A E and WIRTH, C and WIRTH, C}, 
title = {{TRY} - a global database of plant traits}, 
journal = {Global Change Biology}, 
volume = {17}, 
number = {9}, 
pages = {2905--2935}, 
year = {2011}, 
keywords = {Comparative ecology; Database; Environmental gradient; Functional diversity; Global analysis; Global Change; Interspecific variation; Intraspecific variation; Plant functional type; Plant trait; Vegetation models}}

@Article{Bunn:2014ji,
author = {Bunn, Rebecca A and Lekberg, Ylva and Gallagher, Christopher and Rosendahl, S{\o}ren and Ramsey, Philip W}, 
title = {Grassland invaders and their mycorrhizal symbionts: a study across climate and invasion gradients}, 
journal = {Ecology and Evolution}, 
volume = {4}, 
number = {6}, 
pages = {794--805}, 
year = {2014}}

@Article{Yanco2019,
author = {Yanco, Esty and Nelson, Michael Paul and Ramp, Daniel}, 
title = {Cautioning against the overemphasis of normative constructs in conservation decision making}, 
journal = {Conservation Biology}, 
year = {2019}}

@Article{Klein2022,
author = {Klein, J}, 
title = {Improving the reproducibility of findings by updating research methodology.}, 
journal = {Qual Quant}, 
volume = {56}, 
number = {3}, 
pages = {1597--1609}, 
year = {2022}, 
abstract = {The literature discusses causes of low reproducibility of scientific publications. Our article adds another main cause-uncritical adherence to accepted research procedures. This is evident in: (1) anachronistically requiring researchers to base themselves on theoretical background even if the studies cited were not tested for reproducibility; (2) conducting studies suffering from a novelty effect bias; (3) forcing researchers who use data mining methods and field-based theory, with no preliminary theoretical rationale, to present a theoretical background that allegedly guided their work-as a precondition for publication of their findings. It is possible to increase research validity in relation to the above problems by the following means: (1) Conducting a longitudinal study on the same participants and only on them; (2) Trying to shorten the time period between laboratory experiments and those on humans, based on cost-benefit considerations, anchored in ethical norms; (3) Reporting the theoretical background in a causal modular format; (4) Giving incentives to those who meet the above criteria while moderating the pressure for fast output.}, 
location = {School of Education, Bar-Ilan University, 52900 Ramat-Gan, Israel.}}

@Article{Culina2018,
author = {Culina, A and Crowther, TW and Ramakers, JJC and Gienapp, P and Visser, ME}, 
title = {How to do meta-analysis of open datasets.}, 
journal = {Nat Ecol Evol}, 
volume = {2}, 
number = {7}, 
pages = {1053--1056}, 
year = {2018}, 
location = {Netherlands Institute of Ecology (NIOO-KNAW), Wageningen, Netherlands. A.Culina@nioo.knaw.nl. Netherlands Institute of Ecology (NIOO-KNAW), Wageningen, Netherlands. Institute of Integrative Biology, ETH Zurich, Zurich, Switzerland. Netherlands Institute of Ecology (NIOO-KNAW), Wageningen, Netherlands. Netherlands Institute of Ecology (NIOO-KNAW), Wageningen, Netherlands. Netherlands Institute of Ecology (NIOO-KNAW), Wageningen, Netherlands.}}

@Article{Ramoni1992,
author = {Ramoni, Marco and Stefanelli, Mario and Magnani, Lorenzo and Barosi, Giovanni}, 
title = {An epistemological framework for medical knowledge-based systems}, 
journal = {IEEE Transactions on Systems, Man, and Cybernetics}, 
volume = {22}, 
number = {6}, 
pages = {1361--1375}, 
year = {1992}, 
abstract = {An abstraction paradigm for unifying different perspectives concerning the analysis and design of knowledge-based systems (KBSs) is presented. The model accounts for all of the conceptual features of knowledge-based systems, thus making clear which features are intrinsic to the problem and which are artifacts of the implementation. The proposal is based on a two-level analysis of knowledge-based systems: an epistemological and a computational level. At the first level, ontology and inference models of a knowledge-based ...} }

@Article{Riva2010,
author = {Riva, A and Nuzzo, A and Stefanelli, M and Bellazzi, R}, 
title = {An automated reasoning framework for translational research.}, 
journal = {J Biomed Inform}, 
volume = {43}, 
number = {3}, 
pages = {419--427}, 
year = {2010}, 
abstract = {In this paper we propose a novel approach to the design and implementation of knowledge-based decision support systems for translational research, specifically tailored to the analysis and interpretation of data from high-throughput experiments. Our approach is based on a general epistemological model of the scientific discovery process that provides a well-founded framework for integrating experimental data with preexisting knowledge and with automated inference tools. In order to demonstrate the usefulness and power of the proposed framework, we present its application to Genome-Wide Association Studies, and we use it to reproduce a portion of the initial analysis performed on the well-known WTCCC dataset. Finally, we describe a computational system we are developing, aimed at assisting translational research. The system, based on the proposed model, will be able to automatically plan and perform knowledge discovery steps, to keep track of the inferences performed, and to explain the obtained results.}, 
location = {Department of Molecular Genetics and Microbiology, University of Florida, Gainesville, FL, USA. ariva@ufl.edu} }

@Article{Hussain2022,
author = {Hussain, W and Anumalla, M and Catolos, M and Khanna, A and Sta Cruz, MT and Ramos, J and Bhosale, S}, 
title = {Open-source analytical pipeline for robust data analysis, visualizations and sharing in crop breeding.}, 
journal = {Plant Methods}, 
volume = {18}, 
number = {1}, 
pages = {14}, 
year = {2022}, 
abstract = {BACKGROUND: Developing a systematic phenotypic data analysis pipeline, creating enhanced visualizations, and interpreting the results is crucial to extract meaningful insights from data in making better breeding decisions. Here, we provide an overview of how the Rainfed Rice Breeding (RRB) program at IRRI has leveraged R computational power with open-source resource tools like R Markdown, plotly, LaTeX, and HTML to develop an open-source and end-to-end data analysis workflow and pipeline, and re-designed it to a reproducible document for better interpretations, visualizations and easy sharing with collaborators. RESULTS: We reported the state-of-the-art implementation of the phenotypic data analysis pipeline and workflow embedded into a well-descriptive document. The developed analytical pipeline is open-source, demonstrating how to analyze the phenotypic data in crop breeding programs with step-by-step instructions. The analysis pipeline shows how to pre-process and check the quality of phenotypic data, perform robust data analysis using modern statistical tools and approaches, and convert it into a reproducible document. Explanatory text with R codes, outputs either in text, tables, or graphics, and interpretation of results are integrated into the unified document. The analysis is highly reproducible and can be regenerated at any time. The analytical pipeline source codes and demo data are available at https://github.com/whussain2/Analysis-pipeline. CONCLUSION: The analysis workflow and document presented are not limited to IRRI's RRB program but are applicable to any organization or institute with full-fledged breeding programs. We believe this is a great initiative to modernize the data analysis of IRRI's RRB program. Further, this pipeline can be easily implemented by plant breeders or researchers, helping and guiding them in analyzing the breeding trials data in the best possible way.}, 
location = {Rice Breeding Innovation Platform, International Rice Research Institute (IRRI), Los Banos, Laguna, Philippines. waseem.hussain@irri.org. Rice Breeding Innovation Platform, International Rice Research Institute (IRRI), Los Banos, Laguna, Philippines. Rice Breeding Innovation Platform, International Rice Research Institute (IRRI), Los Banos, Laguna, Philippines. Rice Breeding Innovation Platform, International Rice Research Institute (IRRI), Los Banos, Laguna, Philippines. Rice Breeding Innovation Platform, International Rice Research Institute (IRRI), Los Banos, Laguna, Philippines. Rice Breeding Innovation Platform, International Rice Research Institute (IRRI), Los Banos, Laguna, Philippines. Rice Breeding Innovation Platform, International Rice Research Institute (IRRI), Los Banos, Laguna, Philippines.} }

@Article{culina2018,
author = {Culina, Antica and Crowther, Thomas W. and Ramakers, Jip J. C. and Gienapp, Phillip and Visser, Marcel E.}, 
title = {How to do meta-analysis of open datasets}, 
journal = {Nature Ecology \&amp; Evolution}, 
volume = {2}, 
number = {7}, 
pages = {1053--1056}, 
year = {2018} }

@Article{Jankowski2020,
author = {Jankowski, Eric and Ellyson, Neale and Fothergill, Jenny W and Henry, Michael M and Leibowitz, Mitchell H and Miller, Evan D and Alberts, Mone't and Chesser, Samantha and Guevara, Jaime D and Jones, Chris D and Klopfenstein, Mia and Noneman, Kendra K and Singleton, Rachel and Uriarte-Mendoza, Ramon A and Thomas, Stephen and Estridge, Carla E and Jones, Matthew L}, 
title = {Perspective on coarse-graining, cognitive load, and materials simulation}, 
journal = {Computational Materials Science}, 
volume = {171}, 
pages = {109129}, 
year = {2020}, 
keywords = {General Physics and Astronomy; General Materials Science; General Computer Science; Mechanics of Materials; General Chemistry; Computational Mathematics}}

@Article{Simonsohn2020,
author = {Simonsohn, U and Simmons, JP and Nelson, LD}, 
title = {Specification curve analysis.}, 
journal = {Nat Hum Behav}, 
year = {2020}, 
abstract = {Empirical results hinge on analytical decisions that are defensible, arbitrary and motivated. These decisions probably introduce bias (towards the narrative put forward by the authors), and they certainly involve variability not reflected by standard errors. To address this source of noise and bias, we introduce specification curve analysis, which consists of three steps: (1) identifying the set of theoretically justified, statistically valid and non-redundant specifications; (2) displaying the results graphically, allowing readers to identify consequential specifications decisions; and (3) conducting joint inference across all specifications. We illustrate the use of this technique by applying it to three findings from two different papers, one investigating discrimination based on distinctively Black names, the other investigating the effect of assigning female versus male names to hurricanes. Specification curve analysis reveals that one finding is robust, one is weak and one is not robust at all.}, 
location = {ESADE Business School, Behavioral Science, Universitat Ramon Llull, Barcelona, Spain. urisohn@gmail.com. The Wharton School, Operations Information \& Decisions Department, University of Pennsylvania, Philadelphia, PA, USA. Berkeley Haas School of Business Marketing Department, University of California, Berkeley, CA, USA.}}

@Article{A.Ramezan2019,
author = {A. Ramezan, Christopher and A. Warner, Timothy and E. Maxwell, Aaron}, 
title = {Evaluation of Sampling and Cross-Validation Tuning Strategies for Regional-Scale Machine Learning Classification}, 
journal = {Remote Sensing}, 
volume = {11}, 
number = {2}, 
pages = {185}, 
year = {2019}, 
abstract = {<jats:p>High spatial resolution (1--5 m) remotely sensed datasets are increasingly being used to map land covers over large geographic areas using supervised machine learning algorithms. Although many studies have compared machine learning classification methods, sample selection methods for acquiring training and validation data for machine learning, and cross-validation techniques for tuning classifier parameters are rarely investigated, particularly on large, high spatial resolution datasets. This work, therefore, examines four sample selection methods---simple random, proportional stratified random, disproportional stratified random, and deliberative sampling---as well as three cross-validation tuning approaches---k-fold, leave-one-out, and Monte Carlo methods. In addition, the effect on the accuracy of localizing sample selections to a small geographic subset of the entire area, an approach that is sometimes used to reduce costs associated with training data collection, is investigated. These methods are investigated in the context of support vector machines (SVM) classification and geographic object-based image analysis (GEOBIA), using high spatial resolution National Agricultural Imagery Program (NAIP) orthoimagery and LIDAR-derived rasters, covering a 2,609 km2 regional-scale area in northeastern West Virginia, USA. Stratified-statistical-based sampling methods were found to generate the highest classification accuracy. Using a small number of training samples collected from only a subset of the study area provided a similar level of overall accuracy to a sample of equivalent size collected in a dispersed manner across the entire regional-scale dataset. There were minimal differences in accuracy for the different cross-validation tuning methods. The processing time for Monte Carlo and leave-one-out cross-validation were high, especially with large training sets. For this reason, k-fold cross-validation appears to be a good choice. Classifications trained with samples collected deliberately (i.e., not randomly) were less accurate than classifiers trained from statistical-based samples. This may be due to the high positive spatial autocorrelation in the deliberative training set. Thus, if possible, samples for training should be selected randomly; deliberative samples should be avoided.</jats:p} }

@Article{Ramazi2020,
title = {Ramazi2020}}

@Proceedings{Brennan2006,
author = {Brennan, Susan E and Mueller, Klaus and Zelinsky, Greg and Ramakrishnan, IV and Warren, David S and Kaufman, Arie}, 
title = {Toward a multi-analyst, collaborative framework for visual analytics}, 
booktitle = {Toward a multi-analyst, collaborative framework for visual analytics}, 
volume = {2006 IEEE Symposium On Visual Analytics Science And Technology}, 
publisher = {IEEE}, 
pages = {129-136}, 
year = {2006}}

@Article{Marwick2018,
author = {Marwick, Ben and Boettiger, Carl and Mullen, Lincoln}, 
title = {Packaging Data Analytical Work Reproducibly Using R (and Friends)}, 
journal = {The American Statistician}, 
volume = {72}, 
number = {1}, 
pages = {80--88}, 
year = {2018}}

@Book{Gandrud:2016ux,
author = {Gandrud, Christopher}, 
title = {Reproducible Research with R and R Studio, Second Edition}, 
publisher = {CRC Press}, 
year = {2016}, 
abstract = {All the Tools for Gathering and Analyzing Data and Presenting Results Reproducible Research with R and RStudio, Second Edition brings together the skills and tools needed for doing and presenting computational research. Using straightforward examples, the book takes you through an entire reproducible research workflow. This practical workflow enables you to gather and analyze data as well as dynamically present results in print and on the web. New to the Second Edition The rmarkdown package that allows you to create reproducible research documents in PDF, HTML, and Microsoft Word formats using the simple and intuitive Markdown syntax Improvements to RStudio's interface and capabilities, such as its new tools for handling R Markdown documents Expanded knitr R code chunk capabilities The kable function in the knitr package and the texreg package for dynamically creating tables to present your data and statistical results An improved discussion of file organization, enabling you to take full advantage of relative file paths so that your documents are more easily reproducible across computers and systems The dplyr, magrittr, and tidyr packages for fast data manipulation Numerous modifications to R syntax in user-created packages Changes to GitHub's and Dropbox's interfaces Create Dynamic and Highly Reproducible Research This updated book provides all the tools to combine your research with the presentation of your findings. It saves you time searching for information so that you can spend more time actually addressing your research questions. Supplementary files used for the examples and a reproducible research project are available on the author's website.}}

